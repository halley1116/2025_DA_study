{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   Product ID          1000000 non-null  object \n",
      " 1   Product Name        1000000 non-null  object \n",
      " 2   Category            1000000 non-null  object \n",
      " 3   Price               1000000 non-null  float64\n",
      " 4   Discount            1000000 non-null  int64  \n",
      " 5   Tax Rate            1000000 non-null  int64  \n",
      " 6   Stock Level         1000000 non-null  int64  \n",
      " 7   Supplier ID         1000000 non-null  object \n",
      " 8   Customer Age Group  1000000 non-null  object \n",
      " 9   Customer Location   1000000 non-null  object \n",
      " 10  Customer Gender     1000000 non-null  object \n",
      " 11  Shipping Cost       1000000 non-null  float64\n",
      " 12  Shipping Method     1000000 non-null  object \n",
      " 13  Return Rate         1000000 non-null  float64\n",
      " 14  Seasonality         1000000 non-null  object \n",
      " 15  Popularity Index    1000000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(9)\n",
      "memory usage: 122.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import category_encoders as ce\n",
    "# 데이터 불러오기 및 데이터프레임 생성\n",
    "data = pd.read_csv(\"C:/Users/Owner/Desktop/diversified_ecommerce_dataset.csv\")\n",
    "data.head()\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "# 데이터 이해하기\n",
    "\n",
    "# 데이터 요약\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Price        Discount        Tax Rate     Stock Level  \\\n",
      "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
      "mean      1005.120742       12.516955       10.002052      250.028536   \n",
      "std        574.451223        8.539929        3.406026      144.676275   \n",
      "min         10.000000        0.000000        5.000000        0.000000   \n",
      "25%        507.860000        5.000000        8.000000      125.000000   \n",
      "50%       1005.430000       15.000000       10.000000      250.000000   \n",
      "75%       1502.310000       20.000000       12.000000      375.000000   \n",
      "max       2000.000000       25.000000       15.000000      500.000000   \n",
      "\n",
      "        Shipping Cost     Return Rate  Popularity Index  \n",
      "count  1000000.000000  1000000.000000    1000000.000000  \n",
      "mean        24.985224       10.492896         49.970211  \n",
      "std         14.431730        5.484849         29.164875  \n",
      "min          0.000000        1.000000          0.000000  \n",
      "25%         12.490000        5.740000         25.000000  \n",
      "50%         24.970000       10.480000         50.000000  \n",
      "75%         37.470000       15.250000         75.000000  \n",
      "max         50.000000       20.000000        100.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe()) # 기술 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID            0\n",
      "Product Name          0\n",
      "Category              0\n",
      "Price                 0\n",
      "Discount              0\n",
      "Tax Rate              0\n",
      "Stock Level           0\n",
      "Supplier ID           0\n",
      "Customer Age Group    0\n",
      "Customer Location     0\n",
      "Customer Gender       0\n",
      "Shipping Cost         0\n",
      "Shipping Method       0\n",
      "Return Rate           0\n",
      "Seasonality           0\n",
      "Popularity Index      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Product ID']) \n",
    "df = df.drop(columns=['Supplier ID'])\n",
    "df = df.drop(columns=['Product Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "카테고리형 변수의 고유값:\n",
      "Category: ['Apparel' 'Electronics' 'Footwear' 'Books' 'Home Appliances']\n",
      "Customer Age Group: ['35-44' '25-34' '18-24' '55+' '45-54']\n",
      "Customer Location: ['New York, USA' 'London, UK' 'Tokyo, Japan' 'Paris, France' 'Singapore'\n",
      " 'Sydney, Australia' 'Phoenix, USA' 'Cape Town, South Africa'\n",
      " 'Houston, USA' 'Toronto, Canada' 'Chicago, USA' 'Berlin, Germany'\n",
      " 'Dubai, UAE' 'Mumbai, India' 'Los Angeles, USA']\n",
      "Customer Gender: ['Male' 'Female' 'Non-Binary']\n",
      "Shipping Method: ['Standard' 'Overnight' 'Express']\n",
      "Seasonality: ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "# 카테고리형 변수 확인\n",
    "categorical_columns = [ 'Category',\n",
    "       'Customer Age Group', 'Customer Location', 'Customer Gender',\n",
    "       'Shipping Method', 'Seasonality']\n",
    "print(\"\\n카테고리형 변수의 고유값:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "카테고리형 변수의 고유값:\n",
      "Category: ['Apparel' 'Electronics' 'Footwear' 'Books' 'Home Appliances']\n",
      "Customer Age Group: ['35-44' '25-34' '18-24' '55+' '45-54']\n",
      "Customer Location: ['New York, USA' 'London, UK' 'Tokyo, Japan' 'Paris, France' 'Singapore'\n",
      " 'Sydney, Australia' 'Phoenix, USA' 'Cape Town, South Africa'\n",
      " 'Houston, USA' 'Toronto, Canada' 'Chicago, USA' 'Berlin, Germany'\n",
      " 'Dubai, UAE' 'Mumbai, India' 'Los Angeles, USA']\n",
      "Customer Gender: ['Male' 'Female' 'Non-Binary']\n",
      "Shipping Method: ['Standard' 'Overnight' 'Express']\n",
      "Seasonality: ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "# 카테고리형 변수 목록\n",
    "categorical_columns = [ 'Category',\n",
    "                       'Customer Age Group', 'Customer Location', 'Customer Gender',\n",
    "                       'Shipping Method', 'Seasonality']\n",
    "\n",
    "# 각 컬럼의 고유값 출력\n",
    "print(\"\\n카테고리형 변수의 고유값:\")\n",
    "for col in categorical_columns:\n",
    "    unique_values = df[col].unique()\n",
    "    print(f\"{col}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라벨 인코딩: 여러 컬럼\n",
    "le_category = LabelEncoder()\n",
    "df['Category (Label Encoded)'] = le_category.fit_transform(df['Category'])\n",
    "\n",
    "le_location = LabelEncoder()\n",
    "df['Customer Location (Label Encoded)'] = le_location.fit_transform(df['Customer Location'])\n",
    "\n",
    "le_shipping = LabelEncoder()\n",
    "df['Shipping Method (Label Encoded)'] = le_shipping.fit_transform(df['Shipping Method'])\n",
    "\n",
    "le_seasonality = LabelEncoder()\n",
    "df['Seasonality (Label Encoded)'] = le_seasonality.fit_transform(df['Seasonality'])\n",
    "\n",
    "le_age_group = LabelEncoder()\n",
    "df['Customer Age Group (Label Encoded)'] = le_age_group.fit_transform(df['Customer Age Group'])\n",
    "\n",
    "# 2. 이진 인코딩: Customer Gender\n",
    "if 'Customer Gender' in df.columns:  # 컬럼 존재 여부 확인\n",
    "    binary_encoder = ce.BinaryEncoder(cols=['Customer Gender'])\n",
    "    df = binary_encoder.fit_transform(df)\n",
    "else:\n",
    "    print(\"Customer Gender column is missing or already encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 문자열 컬럼 삭제\n",
    "df = df.drop(columns=['Category', 'Customer Age Group', 'Customer Location', 'Shipping Method', 'Seasonality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                                 float64\n",
      "Discount                                int64\n",
      "Tax Rate                                int64\n",
      "Stock Level                             int64\n",
      "Customer Gender_0                       int64\n",
      "Customer Gender_1                       int64\n",
      "Shipping Cost                         float64\n",
      "Return Rate                           float64\n",
      "Popularity Index                        int64\n",
      "Category (Label Encoded)                int64\n",
      "Customer Location (Label Encoded)       int64\n",
      "Shipping Method (Label Encoded)         int64\n",
      "Seasonality (Label Encoded)             int64\n",
      "Customer Age Group (Label Encoded)      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관계수 계산 (수치형 변수만 포함)\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_columns].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Popularity Index와 다른 변수의 상관관계:\n",
      "Popularity Index                      1.000000\n",
      "Return Rate                           0.001648\n",
      "Customer Gender_1                     0.001251\n",
      "Discount                              0.001250\n",
      "Customer Age Group (Label Encoded)    0.001081\n",
      "Category (Label Encoded)              0.000716\n",
      "Tax Rate                              0.000660\n",
      "Shipping Cost                         0.000519\n",
      "Stock Level                           0.000303\n",
      "Customer Gender_0                     0.000275\n",
      "Shipping Method (Label Encoded)       0.000060\n",
      "Seasonality (Label Encoded)           0.000042\n",
      "Price                                -0.000233\n",
      "Customer Location (Label Encoded)    -0.000696\n",
      "Name: Popularity Index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 인기 지수와의 상관관계 확인\n",
    "popularity_corr = correlation_matrix['Popularity Index'].sort_values(ascending=False)\n",
    "print(\"\\nPopularity Index와 다른 변수의 상관관계:\")\n",
    "print(popularity_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "def scale_columns(df, columns_to_scale, scaler_type='standard'):\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported scaler_type. Use 'standard' or 'minmax'.\")\n",
    "\n",
    "    scaled_data = scaler.fit_transform(df[columns_to_scale])\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=[f\"{col}_{scaler_type}_scaled\" for col in columns_to_scale])\n",
    "    df = df.drop(columns=columns_to_scale)  # 기존 컬럼 삭제\n",
    "    df = pd.concat([df, scaled_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 적용\n",
    "columns_standard = ['Price', 'Stock Level', 'Discount', 'Tax Rate', 'Shipping Cost', 'Return Rate']\n",
    "# columns_minmax = ['Discount', 'Tax Rate', 'Shipping Cost', 'Return Rate']\n",
    "df = scale_columns(df, columns_standard, scaler_type='standard')\n",
    "#df = scale_columns(df, columns_minmax, scaler_type='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "스케일링 결과 데이터프레임:\n",
      "   Customer Gender_0  Customer Gender_1  Popularity Index  \\\n",
      "0                  0                  1                56   \n",
      "1                  1                  0                79   \n",
      "2                  1                  1                40   \n",
      "3                  1                  0                93   \n",
      "4                  0                  1                56   \n",
      "\n",
      "   Category (Label Encoded)  Customer Location (Label Encoded)  \\\n",
      "0                         0                                  8   \n",
      "1                         2                                  5   \n",
      "2                         3                                 13   \n",
      "3                         1                                  9   \n",
      "4                         2                                 13   \n",
      "\n",
      "   Shipping Method (Label Encoded)  Seasonality (Label Encoded)  \\\n",
      "0                                2                            1   \n",
      "1                                1                            0   \n",
      "2                                2                            0   \n",
      "3                                2                            0   \n",
      "4                                1                            0   \n",
      "\n",
      "   Customer Age Group (Label Encoded)  Price_standard_scaled  \\\n",
      "0                                   2              -1.655965   \n",
      "1                                   1              -0.424511   \n",
      "2                                   1               1.308448   \n",
      "3                                   0              -1.235755   \n",
      "4                                   4              -0.301367   \n",
      "\n",
      "   Stock Level_standard_scaled  Discount_standard_scaled  \\\n",
      "0                    -0.691396                 -0.880213   \n",
      "1                    -0.179909                 -0.294728   \n",
      "2                     1.506616                 -0.880213   \n",
      "3                    -1.555394                 -0.294728   \n",
      "4                     0.621882                 -0.294728   \n",
      "\n",
      "   Tax Rate_standard_scaled  Shipping Cost_standard_scaled  \\\n",
      "0                  1.467385                      -0.115386   \n",
      "1                  1.467385                      -0.284458   \n",
      "2                 -0.587797                      -0.592807   \n",
      "3                  1.467385                       0.173560   \n",
      "4                  0.586592                       1.451301   \n",
      "\n",
      "   Return Rate_standard_scaled  \n",
      "0                    -1.094451  \n",
      "1                     1.024113  \n",
      "2                    -1.014230  \n",
      "3                    -1.674230  \n",
      "4                    -1.116330  \n"
     ]
    }
   ],
   "source": [
    "# 스케일링 결과 확인\n",
    "print(\"\\n스케일링 결과 데이터프레임:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 'Popularity Index'와의 상관 계수 ---\n",
      "Popularity Index                      1.000000\n",
      "Return Rate_standard_scaled           0.001648\n",
      "Customer Gender_1                     0.001251\n",
      "Discount_standard_scaled              0.001250\n",
      "Customer Age Group (Label Encoded)    0.001081\n",
      "Category (Label Encoded)              0.000716\n",
      "Tax Rate_standard_scaled              0.000660\n",
      "Shipping Cost_standard_scaled         0.000519\n",
      "Stock Level_standard_scaled           0.000303\n",
      "Customer Gender_0                     0.000275\n",
      "Shipping Method (Label Encoded)       0.000060\n",
      "Seasonality (Label Encoded)           0.000042\n",
      "Price_standard_scaled                -0.000233\n",
      "Customer Location (Label Encoded)    -0.000696\n",
      "Name: Popularity Index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 수치형 데이터만 선택\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# 상관 계수 계산\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Popularity Index와의 상관 계수 추출 및 정렬\n",
    "popularity_correlation = correlation_matrix['Popularity Index'].sort_values(ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n--- 'Popularity Index'와의 상관 계수 ---\")\n",
    "print(popularity_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "# Feature와 Target 분리\n",
    "X = df.drop(columns=['Popularity Index'])\n",
    "y = df['Popularity Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest, Ridge, SVR 모델 초기화\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"SVR\": SVR(kernel='rbf')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장용 딕셔너리\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Gender_0                       int64\n",
      "Customer Gender_1                       int64\n",
      "Popularity Index                        int64\n",
      "Category (Label Encoded)                int64\n",
      "Customer Location (Label Encoded)       int64\n",
      "Shipping Method (Label Encoded)         int64\n",
      "Seasonality (Label Encoded)             int64\n",
      "Customer Age Group (Label Encoded)      int64\n",
      "Price_standard_scaled                 float64\n",
      "Stock Level_standard_scaled           float64\n",
      "Discount_standard_scaled              float64\n",
      "Tax Rate_standard_scaled              float64\n",
      "Shipping Cost_standard_scaled         float64\n",
      "Return Rate_standard_scaled           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 각 모델 학습 및 평가\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 예측\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     y_pred_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 각 모델 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # 평가\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # 결과 저장\n",
    "    results[model_name] = {\n",
    "        \"Train RMSE\": train_rmse,\n",
    "        \"Test RMSE\": test_rmse,\n",
    "        \"Train R2\": train_r2,\n",
    "        \"Test R2\": test_r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
